---
title: "PARAMO Tutorial"
output:
  html_document:
    df_print: paged
  pdf_document: default
---



```{r echo=FALSE, message=FALSE}
#include_graphics("../icon-paramo.png")
devtools::load_all("~/repos/scate-shortcourse")
setwd("~/repos/scate-shortcourse/vignettes")
knitr::include_graphics("../icon-paramo.png", dpi=100)
```

***P**hylogenetic **A**ncestral **R**econstruction of **A**natomy by **M**apping **O**ntologies*

The $PARAMO$ pipeline requires three initial pieces of data: a character matrix, a dated phylogeny, and an anatomy ontology. Herein, we use a set of 19 characters from Ontotrace and a large-scale phylogeny of fishes from  [@rabosky2018]. In this demonstration, we are interested in constructing the amalgamated characters for the three levels of amalgamation (=anatomical hierarchy): anatomical dependencies (ADs), body regions (BRs) and entire phenotype (EF). At the BR level, three main body types are considered -- "dermatocranium", "paired fins" and "external integument structures". 

# STEP 1. Initial character matrix

We are going to retrieve our dataset from the Phenoscape Knowledgebase for demonstration purposes as our starting point. We are then going to reconstruct the history of these traits accounting for dependencies among them and amalgamating them according to trait type using the UBERON Anatomy Ontology. 

```{r eval=FALSE}
# Define our traits
terms <- c("dermatocranium", "paired fin", "barbel") 
# Define our taxon
taxon <- "Siluriformes"   

# Apply pk_get_ontotrace_xml over all our traits in our taxon of interest, the Siluriformes. We specify
# variable_only=FALSE to return invariant characters.
nex <- lapply(terms, pk_get_ontotrace_xml, taxon=taxon, variable_only=TRUE)
names(nex) <- terms

.m <- lapply(nex, pk_get_ontotrace)
# Merge together the resulting 3 matrices and remove non-trait data and duplicated columns
m <- reduce(.m, full_join, by="taxa", suffix=c("", ".y"))  
m <- select_at(m, dplyr::vars(-contains("otu"))) # Removes otu data
m <- select_at(m, vars(-contains(".y"))) # Removes duplicated columns

print_coverage(m)
saveRDS(m, file="../data/ontotraceMatrixSiluriformes.rds")
```

To save time, simply run the line below rather than the chunk above.

```{r}
m <- readRDS("../data/ontotraceMatrixSiluriformes.rds")
```


The table that prints out shows the number of taxa for which there is data in the KB ( _coverage_ ) and the proportion of taxa ( _average_ ) that have this trait (all of these are binary, presence/absence characters). This dataset is too big for our demonstration purposes. So lets filter down to a smaller set of traits that will illustrate our process. 

```{r}
dat <- dplyr::select(m,"taxa", 
              "vomer", "accessory vomerine tooth plate",
              "mental barbel", "inner mental barbel", "outer mental barbel", "anterior nasal barbel", "posterior nasal barbel", "maxillary barbel",
              "urohyal", "urohyal lateral process", "urohyal median process", 
              "pectoral fin spine", "anterior dentation of pectoral fin spine", "posterior dentation of pectoral fin spine", 
              "pectoral fin",
              "pelvic fin", "pelvic splint", "pelvic fin ray"
              )

## Let's also clean up some of the species names to only include Genus and species
dat$taxa <- unname(sapply(dat$taxa, function(x) paste(strsplit(x, split=" ")[[1]][1:2], collapse="_")))

dat
```

Now let's load in the Rabosky fish phylogeny and match it to the data using `treeplyr`.

```{r}
tree <- read.tree("../data/actinopt_12k_treePL.tre")
td <- make.treedata(tree, dat)
td
```

We we want to learn about these traits, so we're going to build a nice data table to see what these traits are and their unique identifiers using the KB API and `rphenoscape` function `pk_anatomical_detail`. 

```{r}
traits <- colnames(td$dat)
anatomical_details <- lapply(traits, pk_anatomical_detail) # Query over traits and get anatomical details 

char_info <- list()
char_info$ID <- traits
char_info$char_statement <- sapply(anatomical_details, function(x) x$definition) # Extract definitions
char_info$STATE_0 <- rep(0, length(traits)) # All ontotrace matrices are binary presence/absence
char_info$STATE_1 <- rep(1, length(traits)) # All ontotrace matrices are binary presence/absence
char_info$IRI <- sapply(anatomical_details, function(x) x$id) # Extra a unique URL identifier called an "IRI" 
char_info$IRI <- gsub("http://purl.obolibrary.org/obo/", "", char_info$IRI)
char_info$IRI <- gsub("_", ":", char_info$IRI)

char_info <- data.frame(char_info)
as_tibble(char_info)

```

```{r}
njt <- makeTraitTree(td, skip=NULL)
njt <- root(multi2di(njt), grep("barbel", njt$tip.label))
ontologyHeatMap(td, njt, start=1, cex=0.25)
```

Some of our taxa are really data poor, so let's filter them out and deal with a smaller, more manageable dataset by excluding all taxa that don't have at least 50% of the traits as data.

```{r}
tdf <- filter_coverage(td, traits=0, taxa=0.5)
njt <- makeTraitTree(tdf, skip=NULL)
njt <- root(njt, grep("barbel", njt$tip.label))
ontologyHeatMap(tdf, njt, start=1, cex=0.25)
```

Next, we want to identify the dependencies in our traits by traversing the Uberon Ontology. 

```{r}
dep.mat <- pa_dep_matrix(gsub("N:", "N_", paste0("http://purl.obolibrary.org/obo/", char_info$IRI, sep="")), .names="label", preserveOrder=TRUE)
diag(dep.mat) <- NA
G1 <- graph_from_adjacency_matrix(t(as.matrix(dep.mat)))

plot(G1, vertex.size=5, edge.arrow.size=0.5, vertex.label.cex=0.75)
```


```{r}
## Right now this is done manually, we are working on making it work for the graphs we created above, but lets do it one by one for each module. 
## First, let's find all connected components

con.comp=components(G1, "weak")
M <- list() # Stores our matrices

## Now let's consider mental barbels. We can see from the graph that outer and inner mental barbels depend on a mental barbel being present. We need to amalgamate
## these into a single, multistate character. 

G.mental.barbel <- induced_subgraph(G1, which(con.comp$membership==3))
bin_mats <- init_binary_matrix(G.mental.barbel)
gtraits <- names(bin_mats)
newTraitName <- paste(gtraits, collapse="+")

## Now we iteratively combine the matrices according to the dependencies above
M1 <- comb2matrices(bin_mats$`mental barbel`, bin_mats$`inner mental barbel`, dependent.state = 2) ## Dependent on column 2 of the 'mental barbel' matrix.
M[[newTraitName]] <- comb2matrices(M1, bin_mats$`outer mental barbel`, dependent.state = c(3,4)) ## `outer mental barbel` is dependent on columns 3 and 4 {10, 11} of M1 (i.e. a `mental barbel` is present)
states <- colnames(M[[newTraitName]])
names(states) <- 1:length(states)

## Now we have to recode the data
td.comb <-recode_td(tdf, gtraits, states, hidden0=2:3) ## hidden0 indicates which traits have hidden states when they are absent. These are dependent states.
```


```{r}
## Now let's repeat it for all the other traits; 
############
## Urohyal##
############
g <- induced_subgraph(G1, which(con.comp$membership==7))
bin_mats <- init_binary_matrix(g)
gtraits <- names(bin_mats)
newTraitName <- paste(gtraits, collapse="+")

## Same structure as mental barbels
M1 <- comb2matrices(bin_mats[[1]], bin_mats[[2]], dependent.state = 2) 
M[[newTraitName]] <- comb2matrices(M1, bin_mats[[3]], dependent.state = c(3,4)) 
states <- colnames(M[[newTraitName]])
names(states) <- 1:length(states)

td.comb <-recode_td(td.comb, gtraits, states, hidden0=2:3) ## hidden0 indicates which traits have hidden states when they are absent. These are dependent states.
#################
## Pectoral fin##
#################
g <- induced_subgraph(G1, which(con.comp$membership==8))
mats <- get_graph_matrix(g)
bin_mats <- mats$binary.matrices[mats$nodes.sorted]
gtraits <- names(bin_mats)
newTraitName <- paste(gtraits, collapse="+")

## More complicated structure than the previous two, with more states (16)
M1 <- comb2matrices(bin_mats[[1]], bin_mats[[2]], dependent.state = 2) 
M2 <- comb2matrices(M1, bin_mats[[3]], dependent.state = 4) 
M[[newTraitName]] <- comb2matrices(M2, bin_mats[[4]], dependent.state = c(7,8)) 
 
states <- colnames(M[[newTraitName]])
names(states) <- 1:length(states)

td.comb <-recode_td(td.comb, gtraits, states, hidden0=2:length(gtraits)) ## hidden0 indicates which traits have hidden states when they are absent. These are dependent states.

###############
## Pelvic Fin##
###############
g <- induced_subgraph(G1, which(con.comp$membership==9))
mats <- get_graph_matrix(g)
bin_mats <- mats$binary.matrices[mats$nodes.sorted]
gtraits <- names(bin_mats)
newTraitName <- paste(gtraits, collapse="+")

## Same as first two
M1 <- comb2matrices(bin_mats[[1]], bin_mats[[2]], dependent.state = 2) 
M[[newTraitName]] <- comb2matrices(M1, bin_mats[[3]], dependent.state = c(3,4)) 
states <- colnames(M[[newTraitName]])
names(states) <- 1:length(states)

td.comb <-recode_td(td.comb, gtraits, states, hidden0=2:length(gtraits)) ## hidden0 indicates which traits have hidden states when they are absent. These are dependent states.
states <- setNames(c("0", "1"), 1:2)
td.comb <- recode_td(td.comb,"vomer", states)
td.comb <- recode_td(td.comb, "accessory vomerine tooth plate", states)
td.comb <- recode_td(td.comb, "anterior nasal barbel", states)
td.comb <- recode_td(td.comb, "posterior nasal barbel", states)
td.comb <- recode_td(td.comb, "maxillary barbel", states)


```


We are going to reconstruct our stochastic character maps in RevBayes. In the workshop, we will do a Julia Child-style switch-a-roo and analyze completed analyses, rather than actually running these, because they will take too long. The following code makes a set of customized `.Rev` scripts and datasets that we can use to batch run our analyses. 


```{r eval=FALSE}
write.nexus(td.comb$phy, file="../revbayes/data/fishtree.tre") #This will be provided to you, but if you run your own analysis, you will want to put a tree in place that you can use in RevBayes

MT <- as.data.frame(td.comb$dat)
colnames(MT) <- gsub(" ", "_", colnames(MT))

rownames(MT) <- td.comb$phy$tip.label
for (i in 1:ncol(MT)){
  C.rev<-MT[,i]
  C.rev<-gsub("&", " ", C.rev)
  o <- order(nchar(C.rev))
  
  out<-cbind(rownames(MT), C.rev)
  out <- out[o,]
  write.table(file=paste0("../revbayes/data/", colnames(MT[i]), ".char"), out, quote=F, sep=" ", 
              row.names=F, col.names=F)
}

fl.in  <- readLines("../revbayes/PARAMO2_templ.Rev")


for (i in 1:ncol(MT)){
  fl.in  <- readLines("../revbayes/PARAMO2_templ.Rev")
  fl.in  <- gsub(pattern = "Hymenoptera_br_resolved", replace = "fishtree",
                 x = fl.in)
  fl.in  <- gsub(pattern = "@analysis_name@", replace = paste0(colnames(MT[i])),
                 x = fl.in)

  fl.in <- gsub(pattern = "@chrs_2_read@", 
                replace = paste0("data/", colnames(MT[i]), ".char"), x = fl.in)
  
  if(colnames(MT)[i] %in% gsub(" ", "_", names(M))){
    in.rev<-Mk_Rev(M[[gsub("_", " ", colnames(MT)[i])]])
    
    fl.in <- gsub(pattern = "@numstates@", 
                replace = as.character(max(dim(M[[gsub("_", " ", colnames(MT)[i])]]))), x = fl.in)
    
    fl.in <- gsub(pattern = "@ratematrix@", 
                replace = in.rev, x = fl.in)
  } else {
    
    fl.in <- gsub(pattern = "@numstates@", 
                replace = "2", x = fl.in)
    
    fl.in <- gsub(pattern = "@ratematrix@", 
                replace = ratemat1, x = fl.in)
  }
  
  cat(file=paste0("../revbayes/", colnames(MT[i]), ".Rev"), sep="\n", fl.in)
}



# dir to write and read files
dirW= ("../revbayes/Discr_maps/")
dirR= ("../revbayes/output/")

```

Now we can run our analyses in RevBayes (We will not actually run these). 

```{r eval=FALSE}
setwd("../revbayes/")
# Load these packages if you have access to multiple cores and want to run in parallel
library(foreach)
library(doParallel)
registerDoParallel(cores=10)
res <- foreach(i=1:ncol(MT)) %dopar% {
  cmd <- paste("./rb07 ", colnames(MT)[i], ".Rev &", sep="")
  system(cmd) #Don't actually run!!
}
```
Big long script for amalgamating regions and stochastic maps. I will distill this down and ``pre-cook'' it so it doesn't take so long. 

Our next step is to aggregate the traits by their trait types. This part is not quite done by the phenoscape API, so we're going to interact directly with the UBERON ontology. In the future, this will not be necessary. 

```{r}
# let's modify our character info to drop dependent states and match our new amalgamated characters
char_info_comb <- dropDependentTraits(char_info, dep.mat, td.comb)

c <-  char_info_comb$ID
c <- gsub(" ", "_", c)

#ONT<-get_OBO("http://purl.obolibrary.org/obo/uberon/ext.obo", extract_tags="everything", propagate_relationships = c("part_of", "is_a"))
#saveRDS(ONT, "../data/processed_UBERON.rds")
ONT <- readRDS("../data/processed_UBERON.rds")

annot <- as.list(as.character(char_info_comb$IRI))
names(annot) <- as.character(char_info_comb$ID)
ONT$terms_selected_id <- annot

BR_names <- c("dermatocranium", "paired fin", "external integument structure")
parts <- do.call(rbind,lapply(BR_names, pk_anatomical_detail))
parts$IRI <- sapply(parts$id, strip_IRI)
levelBR <- setNames(parts$IRI, BR_names)     

EF_names <- "anatomical structure"
parts <- do.call(rbind,lapply(EF_names, pk_get_iri, as="uberon"))
parts$IRI <- sapply(parts[,1], strip_IRI)
levelEF <- setNames(parts$IRI, EF_names) 

BR<-lapply(levelBR, function(x)
  get_descendants_chars(ONT, annotations="manual", terms=x)  )

EF<-lapply(levelEF, function(x)
  get_descendants_chars(ONT, annotations="manual", terms=x)  )

cat("\nAggregations by Body Region:\n")
BR
cat("\nAll anatomical entities aggregated:\n")
EF
```

```{r eval=FALSE}
#####################################
# Read a sample of 2 maps from .stm files and save them in the proper format .stmR
#####################################

for (i in 1:length(c))
{
  .tree<-read_Simmap_Rev(paste0(dirR, c[i], ".stm"),
                        start=1, end=2,
                        save = NULL) 
  tree  <- read.simmap(text=.tree, format="phylip")
  
  
  write.simmap(tree, file=paste0(dirW, c[i], ".stmR"))
}
##########

#####################################
# Read stmR, discretize maps, and save each map as a separate rds file; 
#all rds filea for a chracter are stored in a zip archive
#####################################

for (i in 1:length(c))
{ 
  # read in undesritezed trees
  print(paste0("Reading ", c[i]))
  sim=read.simmap(file=paste0(dirW, c[i], ".stmR"), format="phylip")
  
  # discretize trees by looping over sample and saving as rds
  
  for (j in 1:length(sim)){
    tryCatch({
      
      print(paste0("Discretizing tree ", j))
      
      ## errors with na
      
      ##
      
      ##### make trees equal with template
      sim.d<-make_tree_eq(td.comb$phy, sim[[j]], round=5)
      ###
      
      #sim.d<-discr_Simmap_all(sim[[j]], 1000)
      sim.d<-discr_Simmap_all(sim.d, 100)
      
      saveRDS(sim.d, file =  paste0(dirW,c[i], "_", j, ".rds") )
      
    }, error=function(e){
      cat("ERROR :",conditionMessage(e), "\n")
      #errors<-rbind(errors, c(ii,jj))
    }  )
    
  } 
  
  # putting rds files into archive
  files<-paste0(dirW, c[i], "_", c(1:length(sim)), ".rds")
  zip(paste0(dirW, c[i], ".zip"), files=files)
  file.remove(files)
  
}

# close connections
showConnections (all=T)
closeAllConnections()

#############
# Amalgamation at the BR level
#############
# we use the ouput `BR` from the RAC query obtained at Step 3. 
# This ouput contains character IDs for BR terms
# Let's rename those IDs to match the file names of the stochastic maps
#cc<-lapply(BR, function(x) sub("CHAR:", "C", x) )
cc <- BR
cc <-lapply(cc, function(x) gsub(" ", "_", x) )

# creating BR.maps to store the amalagamations
BR.maps<-vector("list", length(BR))
names(BR.maps)<-names(BR)

# run amalgamation using the renamed outputs from RAC query
# this loop construct one amalgamation for each BR term
# the number of amalgamations per term can be specified using `ntrees=`
for (i in 1:length(BR.maps))
{
  map<-paramo(cc[[i]], ntrees=2, dirW=dirW)
  BR.maps[[i]]<-map
}

#############
# Amalgamation at the EF level
#############
# we use the ouput `EF` from the RAC query obtained at Step 3. 
# This ouput contains character IDs for EF term
# Let's rename those IDs to match the file names of the stochastic maps
cc3 <- EF
cc3 <-lapply(cc3, function(x) gsub(" ", "_", x) )

# creating EF.maps to store the amalagamations
EF.maps<-vector("list", length(EF))
names(EF.maps)<-names(EF)

# run amalgamation using the renamed outputs from RAC query
# this code will return 1 amalgamated stochastic map of the EF character
for (i in 1:length(EF.maps))
{
  map<-paramo(cc3[[i]], ntrees=2, dirW=dirW)
  EF.maps[[i]]<-map
}

saveRDS(BR.maps, "../data/BRmaps.rds")
saveRDS(EF.maps, "../data/EFmaps.rds")
```

If you skipped the steps above, no problem, we can simply load the pre-cooked data. 

```{r}
EF.maps <- readRDS("../data/EFmaps.rds")
BR.maps <- readRDS("../data/BRmaps.rds")
```

Let's plot and view the results!

```{r}
#########
# Individual Traits Level
########

hm.palette <- colorRampPalette(brewer.pal(9, 'Set1'), space='Lab')


ymax <- 1.1*length(td.comb$phy$tip.label)
for(i in (1:length(c))){
  trait <- c[i]
  trait <- gsub(" ", "_", trait)
  map <- paramo(trait, ntrees=1, dirW=dirW)
  nstates <- as.numeric(max(colnames(map[[1]]$mapped.edge)))
  try(plotSimmap(map[[1]], pts=F,ftype="off", colors=setNames(hm.palette(nstates+1), 0:nstates), ylim=c(0, ymax)))
  title(paste0("\n ", trait))
}

```


```{r}
#########
# BR level
########
par(mfrow=c(1,3))

# plot one stochastic maps for the head character
states <- unique(names(unlist(BR.maps$dermatocranium[[1]]$maps)))
plotSimmap(BR.maps$dermatocranium[[1]], pts=F,ftype="off",  colors=setNames(hm.palette(length(states)), states))
title("\n Dermatocranium characters")

# plot one stochastic maps for the wings character
states <- unique(names(unlist(BR.maps$'paired fin'[[1]]$maps)))
plotSimmap(BR.maps$`paired fin`[[1]], pts=F,ftype="off", colors=setNames(hm.palette(length(states)), states) )
title("\n Paired Fin characters")

# plot one stochastic maps for the legs character
states <- unique(names(unlist(BR.maps$`external integument structure`[[1]]$maps)))
plotSimmap(BR.maps$`external integument structure`[[1]], pts=F,ftype="off", colors=setNames(hm.palette(length(states)), states))
title("\n Barbel characters")
```

```{r}
#########
# EF level
#########
par(mfrow=c(1,3))
# plot one stochastic maps for the entire phenotype character
# first, let's define color pallette for the characters since it contains many states
tmm<-EF.maps[[1]][[1]]
states <- unique(unlist(lapply(tmm$maps, names)))
# number of states in the character
#length(states)

color<-hm.palette(length(states))

plotSimmap(tmm, setNames(color, states),  lwd=3, pts=F,ftype="off")
title("\n Entire Phenotype character")
```
